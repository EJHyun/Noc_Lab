{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SGD_SVM_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EJHyun/Noc_Lab/blob/master/SGD_SVM_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVv-FxcUmOk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "from sklearn import metrics\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
        "from math import ceil, sqrt\n",
        "import math\n",
        "import copy\n",
        "from cupy.lib import stride_tricks\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import struct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YICmy3smW2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BinarySVC(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, C=1, eta=0.001, batch_size=1, max_epoch=100, random_state=1, pos_=0, mth = 40):\n",
        "        self.lambda_ = 1./C\n",
        "        self.eta = eta\n",
        "        self.batch_size = batch_size\n",
        "        self.max_epoch = max_epoch\n",
        "        self.random_state = random_state\n",
        "        self.pos_ = pos_\n",
        "        self.mth = mth\n",
        "\n",
        "    def hinge_losses(self, x, y):\n",
        "        c = 1./self.lambda_\n",
        "        w_sum = 0\n",
        "        losses = 0\n",
        "        W = []\n",
        "        x_len = len(x)\n",
        "        \n",
        "        inner_ = cp.dot(x,self.w_)\n",
        "        mult_Y = cp.multiply(y,(inner_ + self.b_))\n",
        "        one_ = cp.ones(x_len)\n",
        "        one_ -= mult_Y\n",
        "        \n",
        "        check_max = cp.greater(one_, 0) \n",
        "        \n",
        "        Loss = cp.multiply(one_, check_max)\n",
        "        losses = cp.sum(Loss)\n",
        "\n",
        "        losses /= x_len\n",
        "        \n",
        "        w_sum = cp.sum(cp.multiply(self.w_,self.w_))\n",
        "\n",
        "        w_sum /= (2*c)\n",
        "        losses += w_sum\n",
        "        return losses\n",
        "\n",
        "    def check_min(self, hinge, h_min, isFirst, e):\n",
        "        if(hinge < h_min[0] or isFirst):\n",
        "            h_min[0] = hinge\n",
        "            h_min[1] = self.w_\n",
        "            h_min[2] = self.b_\n",
        "            h_min[3] = e\n",
        "        return self\n",
        "\n",
        "    def plot_loss(self, losses, h_min):\n",
        "    #     plt.figure(figsize=(10,10))\n",
        "    #     plot_name = '{} vs Rest'.format(self.pos_) \n",
        "    #     plt.title(plot_name, size = 15)\n",
        "    #     plt.plot(losses)\n",
        "    #     plt.ylabel('Loss', size = 15)\n",
        "    #     plt.xlabel('Iteration', size = 15)\n",
        "    #     plt.show()\n",
        "          print(\"class\",self.pos_,\"minimum loss = \", h_min[0], \"at\", h_min[3], \"th update\")\n",
        "          return self\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = cp.asarray(X)\n",
        "        y = cp.asarray(y)\n",
        "        r_gen = np.random.RandomState(self.random_state)\n",
        "        self.w_ = r_gen.normal(loc=0.0, scale=0.1, size=1 + X.shape[1])\n",
        "        self.b_, self.w_ = self.w_[0], self.w_[1:]\n",
        "        self.w_ = cp.asarray(self.w_)\n",
        "\n",
        "        losses=[]       #for loss plot\n",
        "        h_min = [0,0,0,0]\n",
        "        eta = 0.0\n",
        "        n_batches = ceil(X.shape[0] / self.batch_size)\n",
        "        Size = self.max_epoch * n_batches\n",
        "        Mth = Size * self.mth / 100\n",
        "        update_ctr = 1\n",
        "\n",
        "        for e in range(self.max_epoch):\n",
        "            idx = [i for i in range(X.shape[0])]\n",
        "            r_gen.shuffle(idx)\n",
        "\n",
        "            for j in range(n_batches):\n",
        "\n",
        "                if(update_ctr - 1 < Mth):\n",
        "                    eta += self.eta / Mth\n",
        "                else:\n",
        "                    eta = (1 + math.cos((update_ctr) * math.pi / Size)) * self.eta / 2\n",
        "                   \n",
        "                batch_idx = idx[self.batch_size * j : self.batch_size * (j+1)]\n",
        "                grad_w, grad_b = self._get_gradient(X[batch_idx], y[batch_idx])\n",
        "                self.w_ = self.w_ - 1 * self.eta * grad_w\n",
        "                self.b_ = self.b_ - 1 * self.eta * grad_b\n",
        "\n",
        "                n = int(Size * 990/1000) # check latter iter\n",
        "                #n = 100\n",
        "                if(update_ctr >= n):\n",
        "                    hinge = self.hinge_losses(X, y)      # calculate hinge loss\n",
        "                    losses.append(hinge)                 # append for plot\n",
        "                    self.check_min(hinge, h_min, update_ctr==n, update_ctr)# update h_min if minimum or First\n",
        "                update_ctr += 1\n",
        "            \n",
        "        self.w_ = h_min[1]\n",
        "        self.b_ = h_min[2]\n",
        "        \n",
        "        self.plot_loss(losses, h_min)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _get_gradient(self, X_batch, y_batch):\n",
        "        grad_w = cp.zeros(X_batch.shape[1])\n",
        "        grad_b = 0\n",
        "        mask = cp.less_equal(cp.multiply(y_batch, cp.dot(X_batch, self.w_))+self.b_, 1)\n",
        "        Xy = cp.multiply(X_batch.T, y_batch)\n",
        "        masked_Xy = cp.multiply(Xy, mask)\n",
        "        grad_w = cp.sum(-masked_Xy, axis=1)\n",
        "        grad_w = grad_w / self.batch_size + self.lambda_ * self.w_\n",
        "\n",
        "        masked_y = cp.multiply(y_batch, mask)\n",
        "        grad_b = cp.sum(-masked_y, axis=0)\n",
        "        grad_b = grad_b / self.batch_size\n",
        "\n",
        "        return grad_w, grad_b\n",
        "\n",
        "class SVC(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, C=1, eta=0.001, batch_size=1, max_epoch=100, random_state=1, mth = 40):\n",
        "        self.C = C\n",
        "        self.eta = eta\n",
        "        self.batch_size = batch_size\n",
        "        self.max_epoch = max_epoch\n",
        "        self.random_state = random_state\n",
        "        self.mth = mth\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = cp.asarray(X)\n",
        "        y = cp.asarray(y)\n",
        "        self.classes_ = cp.unique(y)\n",
        "        self.clfs_per_classs_ = []\n",
        "        # print('[fit]')\n",
        "        for pos in self.classes_:\n",
        "            # print(f\"[{pos}]\", end='')\n",
        "            Y = cp.where(y == pos, 1, -1)\n",
        "            self.clfs_per_classs_.append(BinarySVC(self.C, self.eta, self.batch_size, self.max_epoch, self.random_state, pos_ = pos, mth = self.mth).fit(X, Y))\n",
        "        self.w_ = [clf.w_ for clf in self.clfs_per_classs_]\n",
        "        self.b_ = [clf.b_ for clf in self.clfs_per_classs_]\n",
        "        return self\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.w_, self.b_\n",
        "\n",
        "    def predict(self, X):\n",
        "        # print('\\n[predict]')\n",
        "        X = cp.asarray(X)\n",
        "        self.w_ = cp.stack(self.w_)\n",
        "        self.b_ = cp.stack(self.b_)\n",
        "        hyper_planes = cp.dot(X, self.w_.T) + self.b_\n",
        "        predictions = self.classes_[cp.argmax(hyper_planes, axis=1)]\n",
        "\n",
        "        return cp.asnumpy(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNlGNAnjmmbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_generator(img):\n",
        "    with open(os.path.join(img), 'rb') as fimg:\n",
        "        _, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
        "        img = np.fromfile(fimg, dtype=np.uint8).reshape(num, rows * cols)\n",
        "\n",
        "    def get_img(idx): return img[idx]\n",
        "\n",
        "    for i in range(num):\n",
        "        yield get_img(i)\n",
        "\n",
        "def lbl_generator(label):\n",
        "    with open(os.path.join(label), 'rb') as flbl:\n",
        "        _, num = struct.unpack(\">II\", flbl.read(8))\n",
        "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
        "\n",
        "    def get_label(idx): return lbl[idx]\n",
        "\n",
        "    for i in range(num):\n",
        "        yield get_label(i)\n",
        "\n",
        "def get_data(train_image_path, train_label_path):\n",
        "    x_d1 = img_generator(train_image_path)\n",
        "    y_d1 = lbl_generator(train_label_path)\n",
        "\n",
        "    train_x = [x for x in x_d1]\n",
        "    train_y = [y for y in y_d1]\n",
        "\n",
        "    return train_x, train_y\n",
        "\n",
        "def get_data_test(test_image_path):\n",
        "    x_d1 = img_generator(test_image_path)\n",
        "\n",
        "    train_x = [x for x in x_d1]\n",
        "\n",
        "    return train_x\n",
        "\n",
        "def concat(x1, x2):\n",
        "    xp = cp.get_array_module(x1, x2)\n",
        "    return xp.concatenate((x1, x2), axis=1)\n",
        "\n",
        "def slice2d(x):\n",
        "    xp = cp.get_array_module(x)\n",
        "    length = x.shape[0]\n",
        "    x = x.reshape(length, 28, 28)\n",
        "    new = []\n",
        "    for i in range(length):\n",
        "        new.append(x[i, 3:25, 3:25])\n",
        "    new = np.array(new)\n",
        "    print(new.shape)\n",
        "    return new\n",
        "\n",
        "def poly(x):\n",
        "    x = cp.asarray(x)\n",
        "    x = x.reshape(x.shape[0], 28, 28)\n",
        "    xt = cp.rot90(x, axes=(1,2))\n",
        "    return cp.einsum('ijk,ijk->ijk', x, xt)\n",
        "\n",
        "def conv(x, filter):\n",
        "    x = cp.asarray(x)\n",
        "    filter = cp.asarray(filter)\n",
        "    x = x.reshape(x.shape[0],28,28)\n",
        "    sub_shape = filter.shape\n",
        "    view_shape = tuple(np.subtract(x.shape[1:],sub_shape)+1) + sub_shape\n",
        "    strides = x[0].strides + x[0].strides\n",
        "    result = []\n",
        "    for sample in x:\n",
        "        sub_matrices = stride_tricks.as_strided(sample, view_shape, strides)\n",
        "        masked = cp.einsum('ijkl,kl->ij', sub_matrices, filter)\n",
        "        masked = masked.reshape(masked.shape[0]*masked.shape[1]).tolist()\n",
        "        result.append(masked)\n",
        "    return result\n",
        "\n",
        "def centerize(X_):\n",
        "  ax = int(math.sqrt(len(X_[1])))\n",
        "  index_mat = cp.array(range(ax))\n",
        "  X_ = cp.asarray(X_).reshape(-1, ax, ax)\n",
        "  X = copy.deepcopy(X_)\n",
        "\n",
        "  bin_threshold = 0.3\n",
        "  for i in range(X.shape[0]):\n",
        "    X_[i] = np.where(X_[i] > (255 * bin_threshold), 1, 0)\n",
        "\n",
        "\n",
        "  Xweight = cp.einsum('ijk, j->i', X_, index_mat)\n",
        "  Yweight = cp.einsum('ijk, k->i', X_, index_mat)\n",
        "\n",
        "  X_move = []\n",
        "  Y_move = []\n",
        "  for i in range(X.shape[0]):\n",
        "    X_move.append(int(ax/2) - int(Xweight[i] / cp.sum(X_[i]))) # 왼쪽으로\n",
        "    Y_move.append(int(ax/2) - int(Yweight[i] / cp.sum(X_[i]))) # 위로\n",
        "  for i in range(X.shape[0]):\n",
        "    X[i] = cp.roll(X[i], np.array(X_move[i]), axis = 0)\n",
        "    X[i] = cp.roll(X[i], np.array(Y_move[i]), axis = 1)\n",
        "  return X\n",
        "\n",
        "def reshape2_1D(X):\n",
        "  print(\"Input : \",cp.array(X).shape)\n",
        "  len_ = X.shape[1]\n",
        "  X = X.reshape(-1, len_ * len_)\n",
        "  print(\"Reshaped to 1d : \",cp.array(X).shape)\n",
        "  return X\n",
        "\n",
        "def reshape2_2D(X):\n",
        "  print(\"Input : \",cp.array(X).shape)\n",
        "  ax = int(math.sqrt(len(X[1])))\n",
        "  X = cp.asarray(X).reshape(-1, ax, ax)\n",
        "  print(\"Reshaped to 2D : \",cp.array(X).shape)\n",
        "  return X\n",
        "\n",
        "def crop_center(img,crop_len):\n",
        "    img = cp.asnumpy(img)\n",
        "    y, x = img.shape\n",
        "    startx = x//2-(crop_len//2)\n",
        "    starty = y//2-(crop_len//2)    \n",
        "    return img[starty:starty+crop_len,startx:startx+crop_len]\n",
        "\n",
        "def crop(img_set, crop_len):\n",
        "  result = []\n",
        "  for i in range(img_set.shape[0]):\n",
        "    result.append(crop_center(img_set[i], crop_len))\n",
        "  return np.array(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjx7YN8dmr9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,Y = get_data(\"./newtrain-images-idx3-ubyte\",\n",
        "               \"./newtrain-labels-idx1-ubyte\")\n",
        "X_test = get_data_test(\"./mnist_new_testall-patterns-idx3-ubyte\")\n",
        "\n",
        "print(\"Start Data Centerize\\n\")\n",
        "X = centerize(X)\n",
        "X_test = centerize(X_test)\n",
        "\n",
        "print(\"Start Data Crop\\n\")\n",
        "croplength = 23\n",
        "\n",
        "X_cropped =  crop(cp.asnumpy(X), croplength)\n",
        "X = copy.deepcopy(reshape2_1D(X_cropped))\n",
        "X = cp.asnumpy(X)\n",
        "\n",
        "X_test_cropped =  crop(cp.asnumpy(X_test), croplength)\n",
        "X_test = copy.deepcopy(reshape2_1D(X_test_cropped))\n",
        "X_test = cp.asnumpy(X_test)\n",
        "\n",
        "print(\"Start Data PCA & Polynomial\\n\")\n",
        "pca = PCA(n_components=0.95)\n",
        "poly = PolynomialFeatures(2)\n",
        "\n",
        "X = pca.fit_transform(X)\n",
        "X = poly.fit_transform(X)\n",
        "X = cp.asarray(X)\n",
        "\n",
        "X_test = pca.transform(X_test)\n",
        "X_test = poly.fit_transform(X_test)\n",
        "X_test = cp.array(X_test)\n",
        "\n",
        "print(\"Start Fitting\\n\")\n",
        "clf = SVC(C=1000, eta=0.0008, max_epoch=20, batch_size=256, mth = 30)\n",
        "y_pred =clf.fit(X,Y).predict(X_test)\n",
        "\n",
        "print(\"Start Making prediction text File\\n\")\n",
        "with open('./prediction.txt', 'w') as file:\n",
        "        for i in y_pred:\n",
        "            file.write('%d\\n' % i)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}